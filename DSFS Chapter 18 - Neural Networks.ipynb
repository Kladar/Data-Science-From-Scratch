{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 18 - Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"importing\" from previous chapters. Last task is to clean this up and make a module\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "def dot(v, w):\n",
    "    return sum(v_i * w_i\n",
    "              for v_i, w_i in zip(v,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptrons - the simplest neural net\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    calculation = dot(weights, x) + bias\n",
    "    return step_function(calculation)\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1/ (1 + math.exp(-t)) # smooth approximation of a step function\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\" takes in a neural network, which is a list (layers) of lists (neurons) of lists of weights\n",
    "    and returns some out from the forward propogating input\"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]\n",
    "        output = [neuron_output(neuron, input_with_bias) for neuron in layer]\n",
    "        \n",
    "        outputs.append(output)\n",
    "        input_vector = output\n",
    "    return outputs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [9.38314668300676e-14]\n",
      "0 1 [0.9999999999999059]\n",
      "1 0 [0.9999999999999059]\n",
      "1 1 [9.383146683006828e-14]\n"
     ]
    }
   ],
   "source": [
    "xor_network = [[[20,20,-30],[20,20,-10]],[[-60,60,-30]]]\n",
    "\n",
    "for x in [0,1]:\n",
    "    for y in [0,1]:\n",
    "        print(x,y,feed_forward(xor_network,[x,y])[-1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropogation\n",
    "\n",
    "def backpropagate(network, input_vector, target):\n",
    "\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "\n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                      dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# defeating a captcha\n",
    "\n",
    "# Joel has a cool way to get the raw digits as 5x5 images that I c/p here\n",
    "\n",
    "raw_digits = [\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             1...1\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             1....\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"1...1\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\"]\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    return [1 if c == '1' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "inputs = list(map(make_digit, raw_digits))\n",
    "print(inputs)\n",
    "# zero_digit = [1,1,1,1,1,\n",
    "#              1,0,0,0,1,\n",
    "#              1,0,0,0,1,\n",
    "#              1,0,0,0,1,\n",
    "#              1,1,1,1,1,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the neural net to beat the captcha\n",
    "\n",
    "targets = [[1 if i == j else 0 for i in range(10)] for j in range(10)]\n",
    "\n",
    "random.seed(0)\n",
    "input_size = 25\n",
    "num_hidden = 5\n",
    "output_size = 10\n",
    "\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)] for _ in range(num_hidden)]\n",
    "output_layer = [[random.random() for _ in range(num_hidden + 1)] for _ in range(output_size)]\n",
    "\n",
    "network = [hidden_layer, output_layer]\n",
    "# print(network)\n",
    "# train using backprop\n",
    "\n",
    "for _ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropogate(network, input_vector, target_vector)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024099252251227495,\n",
       " 6.535805275537946e-06,\n",
       " 7.82498285497602e-11,\n",
       " 0.017301919554017466,\n",
       " 0.0011793422713514314,\n",
       " 6.648285303812686e-10,\n",
       " 4.480803518696326e-08,\n",
       " 0.969007735053818,\n",
       " 1.0889968608877994e-08,\n",
       " 2.565215480544878e-08]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(input):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "predict(inputs[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.089379748597191e-09,\n",
       " 0.0015111927756024143,\n",
       " 1.2269558364879473e-08,\n",
       " 0.9449497176995292,\n",
       " 6.320723731390414e-07,\n",
       " 4.772839810266144e-06,\n",
       " 2.566661329270676e-10,\n",
       " 0.009159247290970103,\n",
       " 6.425186805525349e-08,\n",
       " 0.1296193147755028]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obviously it does well on the training set, but lets try some other stylized stuff\n",
    "\n",
    "# stylized 3\n",
    "predict([0,1,1,1,0,\n",
    "        0,0,0,1,1,\n",
    "        0,0,1,1,0,\n",
    "        0,0,0,1,1,\n",
    "        0,1,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8398960946147525e-06,\n",
       " 3.420730717233115e-13,\n",
       " 7.377641549372272e-09,\n",
       " 0.0003464790956137235,\n",
       " 1.3653801311139735e-10,\n",
       " 0.5915126275536223,\n",
       " 2.9656227284800537e-05,\n",
       " 1.7741535556168957e-07,\n",
       " 0.9492129655894995,\n",
       " 0.9961441866705154]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stylized 8\n",
    "predict([0,1,1,1,0,\n",
    "        1,0,0,1,1,\n",
    "        0,1,1,1,0,\n",
    "        1,0,0,1,1,\n",
    "        0,1,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visual the weights to get some intuition on how our neural net is working\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights = network[0][0]\n",
    "abs_weights = [abs(weight) for weight in weights]\n",
    "\n",
    "grid = [abs_weights[row:(row+5)] for row in range(0,25,5)]\n",
    "ax = plt.gca()\n",
    "ax.imshow(grid, cmap=matplotlib.cm.binary, interpolation='none')\n",
    "\n",
    "def patch(x,y, hatch, color):\n",
    "    return matplotlib.patches.Rectangle((x -0.5, y -0.5), 1,1, hatch=hatch, fill=False, color=color)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if weights[5*i + j] < 0:\n",
    "            ax.add_patch(patch(j,i, '/', \"white\"))\n",
    "            ax.add_patch(patch(j,i, '\\\\', \"black\"))\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this technique to look at where the neurons fire and what they are 'looking for' when they break down an image and give their individual opinions on what it could be. The neural net then adds their opinions to get the final prediction. Pretty amazing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This concludes Chapter 18. \n",
    "\n",
    "Neural nets famously \"change everything\" when it comes to prediction and are vital for deep learning applications. For further exploration, there is a machine learing course on Coursera, a book by Michael Nielsen called \"Neural Networks and Deep Learning\", packages like PyBrain and Pylearn2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
