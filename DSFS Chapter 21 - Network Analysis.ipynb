{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 - Network Analysis\n",
    "\n",
    "It's all about nodes and edges, mate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the first chapter\n",
    "\n",
    "import math, random, re\n",
    "from collections import defaultdict, Counter, deque\n",
    "from linear_algebra import dot, get_row, get_column, make_matrix, magnitude, scalar_multiply, shape, distance\n",
    "from functools import partial\n",
    "\n",
    "users = [\n",
    "    { \"id\": 0, \"name\": \"Hero\" },\n",
    "    { \"id\": 1, \"name\": \"Dunn\" },\n",
    "    { \"id\": 2, \"name\": \"Sue\" },\n",
    "    { \"id\": 3, \"name\": \"Chi\" },\n",
    "    { \"id\": 4, \"name\": \"Thor\" },\n",
    "    { \"id\": 5, \"name\": \"Clive\" },\n",
    "    { \"id\": 6, \"name\": \"Hicks\" },\n",
    "    { \"id\": 7, \"name\": \"Devin\" },\n",
    "    { \"id\": 8, \"name\": \"Kate\" },\n",
    "    { \"id\": 9, \"name\": \"Klein\" }\n",
    "]\n",
    "\n",
    "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "               (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
    "\n",
    "# give each user a friends list\n",
    "for user in users:\n",
    "    user[\"friends\"] = []\n",
    "\n",
    "# and populate it\n",
    "for i, j in friendships:\n",
    "    # this works because users[i] is the user whose id is i\n",
    "    users[i][\"friends\"].append(users[j]) # add i as a friend of j\n",
    "    users[j][\"friends\"].append(users[i]) # add j as a friend of i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_paths_from(from_user):\n",
    "    shortest_paths_to = { from_user[\"id\"] : [[]] }\n",
    "    frontier = deque((from_user, friend) for friend in from_user[\"friends\"])\n",
    "    \n",
    "    while frontier:\n",
    "        prev_user, user = frontier.popleft()\n",
    "        user_id = user[\"id\"]\n",
    "        \n",
    "        paths_to_prev = shortest_paths_to[prev_user[\"id\"]]\n",
    "        paths_via_prev = [path + [user_id] for path in paths_to_prev]\n",
    "        \n",
    "        old_paths_to_here = shortest_paths_to.get(user_id, [])\n",
    "        \n",
    "        if old_paths_to_here:\n",
    "            min_path_length = len(old_paths_to_here[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "        \n",
    "        new_paths_to_here = [path_via_prev\n",
    "                             for path_via_prev in paths_via_prev\n",
    "                             if len(path_via_prev) <= min_path_length\n",
    "                             and path_via_prev not in old_paths_to_here]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_here + new_paths_to_here\n",
    "\n",
    "        # add new neighbors to the frontier\n",
    "        frontier.extend((user, friend)\n",
    "                        for friend in user[\"friends\"]\n",
    "                        if friend[\"id\"] not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"shortest_paths\"] = shortest_paths_from(user)\n",
    "\n",
    "for user in users:\n",
    "    user[\"betweenness_centrality\"] = 0.0\n",
    "\n",
    "for source in users:\n",
    "    source_id = source[\"id\"]\n",
    "    for target_id, paths in source[\"shortest_paths\"].items():\n",
    "        if source_id < target_id:   # don't double count\n",
    "            num_paths = len(paths)  # how many shortest paths?\n",
    "            contrib = 1 / num_paths # contribution to centrality\n",
    "            for path in paths:\n",
    "                for id in path:\n",
    "                    if id not in [source_id, target_id]:\n",
    "                        users[id][\"betweenness_centrality\"] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also compute the farness, which we can use to get the closeness centrality\n",
    "\n",
    "def farness(user):\n",
    "    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n",
    "    return sum(len(paths[0])\n",
    "               for paths in user[\"shortest_paths\"].values())\n",
    "\n",
    "for user in users:\n",
    "    user[\"closeness_centrality\"] = 1 / farness(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvector centrality, which is the name of my next EP. Essentially matrix multiplication but brings me back to my\n",
    "# days taking quantum mechanics\n",
    "\n",
    "def matrix_product_entry(A, B, i, j):\n",
    "    return dot(get_row(A, i), get_column(B, j))\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    n1, k1 = shape(A)\n",
    "    n2, k2 = shape(B)\n",
    "    if k1 != n2:\n",
    "        raise ArithmeticError(\"incompatible shapes!\")\n",
    "\n",
    "    return make_matrix(n1, k2, partial(matrix_product_entry, A, B))\n",
    "\n",
    "def vector_as_matrix(v):\n",
    "    \"\"\"returns the vector v (represented as a list) as a n x 1 matrix\"\"\"\n",
    "    return [[v_i] for v_i in v]\n",
    "\n",
    "def vector_from_matrix(v_as_matrix):\n",
    "    \"\"\"returns the n x 1 matrix as a list of values\"\"\"\n",
    "    return [row[0] for row in v_as_matrix]\n",
    "\n",
    "def matrix_operate(A, v):\n",
    "    v_as_matrix = vector_as_matrix(v)\n",
    "    product = matrix_multiply(A, v_as_matrix)\n",
    "    return vector_from_matrix(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalues are scalars on vectors that point in the same direction as our matrix\n",
    "\n",
    "def find_eigenvector(A, tolerance=0.00001):\n",
    "    guess = [1 for __ in A]\n",
    "\n",
    "    while True:\n",
    "        result = matrix_operate(A, guess)\n",
    "        length = magnitude(result)\n",
    "        next_guess = scalar_multiply(1/length, result)\n",
    "\n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            return next_guess, length # eigenvector, eigenvalue\n",
    "\n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best to read the book here about eigenvector centrality. Very hard to sum up.\n",
    "def entry_fn(i, j):\n",
    "    return 1 if (i, j) in friendships or (j, i) in friendships else 0\n",
    "\n",
    "n = len(users)\n",
    "adjacency_matrix = make_matrix(n, n, entry_fn)\n",
    "\n",
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)\n",
    "\n",
    "# eigenvector centralitites are numbers, one per user, that are the constant multiple of her neighbors numbers. In other \n",
    "# words, being connected to people who are themselves central. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we have directed rather than undirected networks, say of endorsements?\n",
    "\n",
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2), (2, 1), (1, 3),\n",
    "                (2, 3), (3, 4), (5, 4), (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n",
    "\n",
    "for user in users:\n",
    "    user[\"endorses\"] = []       # add one list to track outgoing endorsements\n",
    "    user[\"endorsed_by\"] = []    # and another to track endorsements\n",
    "\n",
    "for source_id, target_id in endorsements:\n",
    "    users[source_id][\"endorses\"].append(users[target_id])\n",
    "    users[target_id][\"endorsed_by\"].append(users[source_id])\n",
    "\n",
    "\n",
    "endorsements_by_id = [(user[\"id\"], len(user[\"endorsed_by\"]))\n",
    "                      for user in users]\n",
    "\n",
    "sorted(endorsements_by_id,\n",
    "       key=lambda pair: pair[1],\n",
    "       reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how PageRank works! Amazing. We have a set amount of rank to distribute and then we update based on centrality\n",
    "\n",
    "def page_rank(users, damping = 0.85, num_iters = 100):\n",
    "\n",
    "    # initially distribute PageRank evenly\n",
    "    num_users = len(users)\n",
    "    pr = { user[\"id\"] : 1 / num_users for user in users }\n",
    "\n",
    "    # this is the small fraction of PageRank\n",
    "    # that each node gets each iteration\n",
    "    base_pr = (1 - damping) / num_users\n",
    "\n",
    "    for __ in range(num_iters):\n",
    "        next_pr = { user[\"id\"] : base_pr for user in users }\n",
    "        for user in users:\n",
    "            # distribute PageRank to outgoing links\n",
    "            links_pr = pr[user[\"id\"]] * damping\n",
    "            for endorsee in user[\"endorses\"]:\n",
    "                next_pr[endorsee[\"id\"]] += links_pr / len(user[\"endorses\"])\n",
    "\n",
    "        pr = next_pr\n",
    "\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This concludes Chapter 21.\n",
    "\n",
    "For further exploration check out more notions of centrality, though what we used are the most popular.\n",
    "\n",
    "NetworkX is a pythonlibrary for network analysis. Gephi is a GUI network visualization tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
